{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f40df0",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction – Machine Learning Project\n",
    "\n",
    "This notebook builds an end-to-end machine learning pipeline to predict customer churn using the Telco Customer Churn dataset. The goal is to identify customers who are at high risk of leaving so that the business can take proactive retention measures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920a2f68",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Customer churn is one of the most important business problems for subscription-based services.  \n",
    "The objective of this project is to:\n",
    "\n",
    "- Explore customer behaviour  \n",
    "- Identify major churn drivers  \n",
    "- Build machine learning models that can classify at-risk customers  \n",
    "- Provide business recommendations based on insights  \n",
    "\n",
    "We use the **Telco Customer Churn** dataset, which includes information on customer demographics, service usage, account details, and churn labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0de9602",
   "metadata": {},
   "source": [
    "## 2. Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d906870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import(\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    confusion_matrix,\n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df = pd.read_csv(r\"D:\\Downlaods\\WA_Fn-UseC_-Telco-Customer-Churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152a0094",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview\n",
    "\n",
    "The Telco dataset contains:\n",
    "\n",
    "- **7043 rows** (customers)  \n",
    "- **20+ features** including:\n",
    "  - Customer demographics  \n",
    "  - Subscription details  \n",
    "  - Billing information  \n",
    "  - Service usage  \n",
    "- **Target variable:** `Churn` (Yes/No)\n",
    "\n",
    "Before modeling, we explore the dataset to understand trends and patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a099e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a931aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd14a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54dd696",
   "metadata": {},
   "source": [
    "## 3. Cleaning and formatting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71af43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731a003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d7d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b27914",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA helps us understand how customers behave and which groups are more likely to churn.\n",
    "\n",
    "Key areas explored:\n",
    "\n",
    "- Churn distribution  \n",
    "- Tenure patterns  \n",
    "- Monthly charges  \n",
    "- Contract type  \n",
    "- Correlation between features  \n",
    "\n",
    "These insights guide feature engineering and model selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6361ae1d",
   "metadata": {},
   "source": [
    "### 4.1 Churn Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf560576",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df['Churn'])\n",
    "plt.title(\"Churn Distribution\")\n",
    "plt.show()\n",
    "\n",
    "df[\"Churn\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5bdf31",
   "metadata": {},
   "source": [
    "\n",
    "The churn distribution is imbalanced, with approximately:\n",
    "\n",
    "- **73% Non-churners**\n",
    "- **27% Churners**\n",
    "\n",
    "This imbalance means evaluation metrics like **accuracy** alone are unreliable.  \n",
    "We will therefore focus on:\n",
    "\n",
    "- Recall (churn class)  \n",
    "- F1-score  \n",
    "- ROC-AUC  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf10708",
   "metadata": {},
   "source": [
    "### 4.2 Tenure Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313efaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[\"tenure\"], kde = True)\n",
    "plt.title(\"Tenure Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5093cc1",
   "metadata": {},
   "source": [
    "The distribution of customer tenure reveals several important patterns:\n",
    "\n",
    "There is a large spike at very low tenure (0–5 months)\n",
    "→ Indicates many customers leave early after onboarding\n",
    "\n",
    "Another noticeable spike appears around 70–72 months\n",
    "→ Customers who have stayed long are much less likely to churn\n",
    "\n",
    "The distribution dips in the mid-range (20–50 months)\n",
    "\n",
    "Customers with **very low tenure (0–6 months)** show the highest churn.  \n",
    "This indicates that dissatisfaction starts early, highlighting the importance of strong onboarding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b7a3b",
   "metadata": {},
   "source": [
    "### 4.3 Monthly Charges Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9192599",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[\"MonthlyCharges\"], kde=True)\n",
    "plt.title(\"Monthly Charge Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fdbf60",
   "metadata": {},
   "source": [
    "The distribution of MonthlyCharges reveals:\n",
    "\n",
    "A small cluster of customers paying very low charges (~$20–30)\n",
    "\n",
    "A major concentration around $70–100\n",
    "\n",
    "A long tail reaching above $100\n",
    "\n",
    "Customers with higher monthly charges tend to churn more often:\n",
    "\n",
    "Higher cost → increased dissatisfaction\n",
    "\n",
    "Customers may switch to cheaper competitors\n",
    "\n",
    "This aligns with industry research: pricing pressure is a primary driver of churn in telecom/data services.\n",
    "\n",
    "\n",
    "Higher monthly charges correlate strongly with churn.  \n",
    "Customers paying more tend to be more dissatisfied or price-sensitive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80fa404",
   "metadata": {},
   "source": [
    "### 4.4 Contract Type vs Churn Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x= 'Contract', hue = \"Churn\")\n",
    "plt.title(\"Churn By Contract Type\")\n",
    "plt.xticks(rotation= 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075e9c4e",
   "metadata": {},
   "source": [
    "Month-to-month contracts have the highest churn\n",
    "\n",
    "Very high churn rate\n",
    "\n",
    "Minimal commitment\n",
    "\n",
    "Customers can leave easily\n",
    "\n",
    "One-year contracts have significantly lower churn\n",
    "\n",
    "Moderate retention effect\n",
    "\n",
    "Two-year contracts have the lowest churn\n",
    "\n",
    "Long-term contracts stabilize retention\n",
    "\n",
    "Customers with long-term commitments rarely churn early\n",
    "\n",
    "\n",
    "Contract type plays a crucial role:\n",
    "\n",
    "- **Month-to-month customers** churn the most  \n",
    "- **One-year contracts** have moderate churn  \n",
    "- **Two-year contract customers** churn the least  \n",
    "\n",
    "This confirms that long-term commitments stabilize retention.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8104079",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing\n",
    "\n",
    "To prepare the data for modeling:\n",
    "\n",
    "1. Convert `TotalCharges` to numeric  \n",
    "2. Handle missing values  \n",
    "3. Drop unnecessary identifiers (`customerID`)  \n",
    "4. Encode categorical variables using one-hot encoding  \n",
    "5. Scale numerical features using StandardScaler  \n",
    "6. Train-test split (80/20)\n",
    "\n",
    "Preprocessing ensures the dataset is clean and machine-learning ready.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15efddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors = 'coerce')\n",
    "\n",
    "df[\"TotalCharges\"] = df[\"TotalCharges\"].fillna(df[\"TotalCharges\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Churn\"] = df[\"Churn\"].map({\"Yes\":1, \"No\":0})\n",
    "df_encoded = pd.get_dummies(df.drop([\"customerID\"], axis = 1), drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f06264",
   "metadata": {},
   "source": [
    "### Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4234e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df_encoded.corr(), cmap='coolwarm', center=0)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39a5484",
   "metadata": {},
   "source": [
    "### Correlation Heatmap\n",
    "\n",
    "The heatmap highlights:\n",
    "\n",
    "- Strong negative correlation between **tenure** and **churn**\n",
    "- Strong positive correlation between:\n",
    "  - Month-to-month contracts and churn\n",
    "  - Electronic check payment and churn\n",
    "  - Fiber optic internet and churn  \n",
    "\n",
    "These will be important features for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c15a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b095874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c361b4e8",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "We train three baseline models:\n",
    "\n",
    "- Logistic Regression  \n",
    "- Random Forest  \n",
    "- XGBoost  \n",
    "\n",
    "These models provide a good mix of:\n",
    "\n",
    "- Linear interpretability (LR)  \n",
    "- Non-linear structure (RF)  \n",
    "- Boosted performance (XGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e312e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df_encoded.drop('Churn', axis=1)\n",
    "y = df_encoded[\"Churn\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=13, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b5ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "x_train = scalar.fit_transform(x_train)\n",
    "x_test = scalar.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9eb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(model, parameters, model_type):\n",
    "    random_search = RandomizedSearchCV(model, parameters,n_iter=50, scoring='roc_auc', cv = 5, n_jobs=1, verbose=1)\n",
    "    random_search.fit(x_train,y_train)\n",
    "    best_model = random_search.best_estimator_\n",
    "    print(f\"Best {model_type} Parameters:\", random_search.best_params_)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=500)\n",
    "\n",
    "lr_model.fit(x_train, y_train)\n",
    "pred = lr_model.predict(x_test)\n",
    "probs = lr_model.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b125947",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=13, class_weight='balanced')\n",
    "rf_parameter_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 6],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "best_rf_model = random_search(rf_classifier, rf_parameter_grid, \"Random Forest\")\n",
    "rf_pred = best_rf_model.predict(x_test)\n",
    "rf_probs = best_rf_model.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00581224",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = XGBClassifier(eval_metric = 'logloss')\n",
    "xgb_parameter_grid = {\n",
    "    'n_estimators': [200, 300, 500, 800],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5, 6, 8],\n",
    "    'subsample': [0.6, 0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 5],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [1, 2, 5]\n",
    "}\n",
    "best_xgb_model = random_search(xgb_classifier, xgb_parameter_grid, \"XGBoost\")\n",
    "\n",
    "\n",
    "best_xgb_model.fit(x_train, y_train)\n",
    "xgb_pred = best_xgb_model.predict(x_test)\n",
    "xgb_probs = best_xgb_model.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e9c34",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "Models are evaluated using:\n",
    "\n",
    "- **Recall (Churn class)** – priority metric  \n",
    "- **F1-score (Churn)**  \n",
    "- **Accuracy**  \n",
    "- **ROC-AUC**  \n",
    "\n",
    "Why recall matters:\n",
    "We want to catch as many churners as possible — missing a churner is costlier than mistakenly flagging a loyal customer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a28fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression Model Classification Report\")\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "print(\"Random Forest Classifier Classification Report:\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "print(\"XGBoost Classifier Classification Report:\")\n",
    "print(classification_report(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae212a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm  =  confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot = True, fmt = \"d\" , cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Prediction\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_test, rf_pred, \"Random Forest Classifier Confusion Matrix\")\n",
    "plot_confusion_matrix(y_test, xgb_pred, \"XGBOOST Classifier Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d274e32",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "\n",
    "The ROC curve compares the true positive rate vs. false positive rate.  \n",
    "The **AUC score** summarizes model predictive power:\n",
    "\n",
    "- 0.5 = random guessing  \n",
    "- 1.0 = perfect classifier  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dccb041",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression ROC-AUC:\", roc_auc_score(y_test, probs))\n",
    "print(\"Random Forest ROC-AUC:\", roc_auc_score(y_test, rf_probs))\n",
    "print(\"XGBoost ROC-AUC:\", roc_auc_score(y_test, xgb_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, probs)\n",
    "fpr_rf, tpr_rf,_ = roc_curve(y_test, rf_probs)\n",
    "fpr_xgb, tpr_xgb,_ = roc_curve(y_test, xgb_probs)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(fpr_lr, tpr_lr, label = \"Logistic Regression\")\n",
    "plt.plot(fpr_rf, tpr_rf, label = \"Random Forest\")\n",
    "plt.plot(fpr_xgb, tpr_xgb, label = \"XGBOOST\")\n",
    "plt.plot([0,1],[0,1], linestyle = '--')\n",
    "\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"Flase Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab9b44",
   "metadata": {},
   "source": [
    "## 7. Feature Importance (XGBoost)\n",
    "\n",
    "XGBoost provides feature importance based on gain (improvement in splits).  \n",
    "Top churn drivers include:\n",
    "\n",
    "- Fiber optic internet  \n",
    "- Month-to-month contract  \n",
    "- Electronic check payment  \n",
    "- Low tenure  \n",
    "- Lack of security/tech support add-ons  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dict = best_xgb_model.get_booster().get_score(importance_type = 'gain')\n",
    "mapped_importance = {\n",
    "    x.columns[int(k[1:])]: v for k, v in importance_dict.items()\n",
    "}\n",
    "\n",
    "mapped_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': mapped_importance.keys(),\n",
    "    'importance': mapped_importance.values()\n",
    "})\n",
    "\n",
    "xgb_importance = xgb_importance.sort_values(by = 'importance', ascending= False)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.barh(xgb_importance['feature'][:15], xgb_importance['importance'][:15])\n",
    "plt.title(\"Top 15 XGBoost Feature Importance\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c39e7",
   "metadata": {},
   "source": [
    "## 8. Business Insights\n",
    "\n",
    "Based on the model’s feature importance:\n",
    "\n",
    "1. **Promote longer-term contracts**  \n",
    "2. **Improve onboarding for new customers**  \n",
    "3. **Investigate fiber optic dissatisfaction**  \n",
    "4. **Encourage auto-pay instead of electronic checks**  \n",
    "5. **Bundle security/tech-support with subscriptions**\n",
    "\n",
    "These insights help significantly reduce churn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de6c18a",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "This project successfully:\n",
    "\n",
    "- Explored the Telco dataset  \n",
    "- Identified key churn factors  \n",
    "- Built ML models to predict churn  \n",
    "- Selected the best model (XGBoost)  \n",
    "- Delivered actionable business recommendations  \n",
    "\n",
    "The pipeline can be extended using:\n",
    "- SMOTE oversampling  \n",
    "- SHAP interpretability  \n",
    "- Deployment via Streamlit/Flask  \n",
    "- A Power BI dashboard  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4996116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
